% Breakpoint
% Sébastien Boisgérault
% Saturday, 08 March 2014


Preamble
--------------------------------------------------------------------------------

    from __future__ import division
    import time

Using Generator to Break Long-Running Functions
--------------------------------------------------------------------------------

Basic operation:

    result = compute(result)

Encapsulate instead and call the function ?

    def compute(value):
        time.sleep(0.1)
        return value + 1

That's our simulation of compute computation. Long-running operations are
sequences of such operations.

    def count_to_three():
        result = 0
        result = compute(result)
        result = compute(result)
        result = compute(result)
        return result

Using it:

    >>> count_to_three():
    3

Intermediate version ? With `yield` and `yield None, result` at the end ?
That seems artificial (the end), could we accept `yield result` without
ambiguity ? Unfortunately, no, we would need an extra option in the 
decorator and it's not worth it. State that it's a convention we use 
that is going to get explained shortly.

Generator version (minimal):

    def count_to_three():
        result = 0
        yield
        result = compute(result)
        yield
        result = compute(result)
        yield
        result = compute(result)
        yield None, result

Using it:

    >>> counter = count_to_three()
    >>> counter.next()
    >>> counter.next()
    >>> counter.next()
    >>> counter.next()
    None, 3


Generator version: progress and partial result

    def count_to_three():
        result = 0
        yield 0 / 3, result
        result = compute(result)
        yield 1 / 3, result
        result = compute(result)
        yield 2 / 3, result
        result = compute(result)
        yield 3 / 3, result

generator version with progress and partial result: explain 3 ops,
hence progress computation. Explain partial result. Those two results
are optional (replacable by None). If you don't care at all, `yield`
(aka `yield None`) is OK too.

State that progress is optional (`None` if you don't know)

Using it:

    >>> counter = count_to_three()
    >>> counter.next()
    (0.0, 0)
    >>> counter.next()
    (0.3333333333333333, None)
    >>> counter.next()
    (0.6666666666666666, None)
    >>> counter.next()
    (1.0, None)


Loop version, explicit progress, partial result

    def count_to(n):
        result = 0
        for i in range(n):
            result = compute(result)
        return result

Using it:

    >>> count_to(3)
    3

    def count_to(n):
        result = 0
        for i in range(n):
            progress = i / n
            yield progress, result 
            result = compute(result)
        return result


Breakpoint Decorator
--------------------------------------------------------------------------------


Restore the original function behavior from the generator:

    @breakpoint()
    def count_to(n):
        result = 0
        for i in range(n):
            progress = i / n
            yield progress, result 
            result = compute(result)
        return result

Using it:

    >>> count_to(3)
    3

So why the hell did we tweak the original function ? Because we
have new options now such as: because now we can track the evolution
of the computation. For example, display partial results:

    def partial():
        def handler(**kwargs):
            print kwargs.get("progress"), kwargs.get("result")
        return handler

Decorate `count_to` like this:

    @breakpoint(handler=partial)
    def count_to(n):
        result = 0
        for i in range(n):
            progress = i / n
            yield progress, result 
            result = compute(result)
        return result

Use it like this:

    >>> count_to(3)
    (0.0, 0)
    (0.3333333333333333, 1)
    (0.6666666666666666, 2)
    (1.0, 3)
    3

Available information for the handler: includes what you returned in the yield, 
that is `progress`, `result`. There is more, so make sure to use `**kwargs`.

Explain handler factory (closure): every time your run, a new instance of the 
handler is generated. For example:

    def partial():
       start = True
       def handler(**kwargs):
           nonlocal start
           if start:
               print "first handler call"
               start = False
           print kwargs.get("progress"), kwargs.get("result")
       return handler

Alternate implementation (class-based):

    class partial(object):
        def __init__(self):
            self.start = True
        def __call__(self, **kwargs):
            if self.start:
                print "first handler call"
                self.start = False
            print kwargs.get("progress"), kwargs.get("result")






Time Target
--------------------------------------------------------------------------------

New assumption if you use `dt`: you call `yield` at regular frequency.

Explain `elapsed` and `result`.

